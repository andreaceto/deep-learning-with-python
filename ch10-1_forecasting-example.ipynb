{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b4cdb7e",
   "metadata": {},
   "source": [
    "# A temperature-forecasting example\n",
    "**Problem**: given a Time Series of hourly measurements (humidity, pressure, etc.), recorded over the recent past by a set of sensors on the roof of a building, we want to predict the temperature 24 hours in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c17a4ca",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "We’ll work with a weather timeseries [dataset](https://www.bgc-jena.mpg.de/wetter/) recorded at the weather station at the Max Planck Institute for Biogeochemistry in Jena, Germany.\n",
    "\n",
    "In this dataset, 14 different quantities (such as temperature, pressure, humidity, wind direction, and so on) were recorded every 10 minutes over several years. The original data goes back to 2003, but the subset of the data we’ll download is limited to 2009–2016."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9e012f",
   "metadata": {},
   "source": [
    "### Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4146d030",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "!wget https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
    "!unzip jena_climate_2009_2016.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f882df",
   "metadata": {},
   "source": [
    "### Inspecting the data of the Jena weather dataset\n",
    "The following snippet outputs a count of $420,551$ lines of data (each line is a timestep: a record of a date and 14 weather-related values), as well as its header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a3a671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "fname = os.path.join(\"jena_climate_2009_2016.csv\")\n",
    "\n",
    "with open(fname) as f:\n",
    "    data = f.read()\n",
    "\n",
    "lines = data.split(\"\\n\")\n",
    "header = lines[0].split(\",\")\n",
    "lines = lines[1:]\n",
    "print(header)\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0b5700",
   "metadata": {},
   "source": [
    "### Parsing the data\n",
    "Now, convert all $420,551$ lines of data into NumPy arrays:\n",
    "- One array for the temperature (in degrees Celsius);\n",
    "- Another one for the rest of the data—the features we will use to predict future temperatures.\n",
    "\n",
    "Note that we discard the _“Date Time”_ column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b44120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "temperature = np.zeros((len(lines),))\n",
    "raw_data = np.zeros((len(lines), len(header) - 1))\n",
    "for i, line in enumerate(lines):\n",
    "    values = [float(x) for x in line.split(\",\")[1:]]\n",
    "    temperature[i] = values[1]\n",
    "    raw_data[i, :] = values[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13472767",
   "metadata": {},
   "source": [
    "### Plotting the temperature timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aa4c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(range(len(temperature)), temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a11d62",
   "metadata": {},
   "source": [
    "We can clearly see the yearly **periodicity** of temperature $-$ the data spans 8 years.\n",
    "\n",
    "Periodicity over multiple timescales is an important and very common property of timeseries data. Whether you’re looking at the weather, mall parking occupancy, traffic to a website, sales of a grocery store, or steps logged in a fitness tracker, you’ll see daily cycles and yearly cycles (human-generated data also tends to feature weekly cycles).\n",
    "\n",
    "When exploring your data, make sure to look for these patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8424ee88",
   "metadata": {},
   "source": [
    "### Plotting the first 10 days of the temperature timeseries\n",
    "Because the data is recorded every 10 minutes, you get $24 \\times 6 = 144$ data points per day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e0531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1440), temperature[:1440])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427405cf",
   "metadata": {},
   "source": [
    "On this plot, we can see daily periodicity, especially for the last 4 days. Also note that this 10-day period must be coming from a fairly cold winter month."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6837b4",
   "metadata": {},
   "source": [
    "### Computing the number of samples we’ll use for each data split\n",
    "We’ll use the first $50%$ of the data for training, the following $25%$ for validation, and the last $25%$ for testing.\n",
    "\n",
    "When working with timeseries data, it’s important to use validation and test data that is more recent than the training data, because you’re trying to **predict the future given the past**, not the reverse, and your validation/test splits should reflect that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051a4e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_samples = int(0.5 * len(raw_data))\n",
    "num_val_samples = int(0.25 * len(raw_data))\n",
    "num_test_samples = len(raw_data) - num_train_samples - num_val_samples\n",
    "\n",
    "print(\"num_train_samples:\", num_train_samples)\n",
    "print(\"num_val_samples:\", num_val_samples)\n",
    "print(\"num_test_samples:\", num_test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5397f55",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "The exact formulation of the problem will be as follows:\n",
    "\n",
    "_<<Given data covering the previous five days and sampled once per hour, can we predict the temperature in 24 hours?>>_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cb3202",
   "metadata": {},
   "source": [
    "### Normalizing the data\n",
    "First, let’s preprocess the data to a format a neural network can ingest.\n",
    "\n",
    "The data is already numerical, so you don’t need to do any vectorization. But each timeseries in the data is on a different scale (for example, atmospheric pressure, measured in _mbar_, is around $1,000$, while H2OC, measured in _millimoles per mole_, is around $3$). We’ll normalize each timeseries independently so that they all take small values on a similar scale.\n",
    "\n",
    "We’re going to use the first $210,225$ timesteps as training data, so we’ll compute the mean and standard deviation only on this fraction of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93500026",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = raw_data[:num_train_samples].mean(axis=0)\n",
    "raw_data -= mean\n",
    "std = raw_data[:num_train_samples].std(axis=0)\n",
    "raw_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c08e8d",
   "metadata": {},
   "source": [
    "### Instantiating datasets for training, validation, and testing\n",
    "Next, let’s create a _Dataset_ object that yields batches of data from the past five days along with a target temperature 24 hours in the future.\n",
    "\n",
    "Because the samples in the dataset are highly redundant (sample $N$ and sample $N + 1$ will have most of their timesteps in common), it would be wasteful to explicitly allocate memory for every sample.\n",
    "\n",
    "Instead, we’ll generate the samples on the fly while only keeping in memory the original ```raw_data``` and ```temperature``` arrays, and nothing more.\n",
    "\n",
    "We’ll use ```timeseries_dataset_from_array()``` to instantiate three datasets: one for training, one for validation, and one for testing.\n",
    "\n",
    "We’ll use the following parameter values:\n",
    "- ```sampling_rate = 6```—Observations will be sampled at one data point per hour: we will only keep one data point out of 6;\n",
    "- ```sequence_length = 120```—Observations will go back 5 days (120 hours);\n",
    "- ```delay = sampling_rate * (sequence_length + 24 - 1)```—The target for a sequence will be the temperature 24 hours after the end of the sequence.\n",
    "\n",
    "When making the training dataset, we’ll pass ```start_index = 0``` and ```end_index = num_train_samples``` to only use the first $50%$ of the data.\n",
    "\n",
    "For the validation dataset, we’ll pass ```start_index = num_train_samples``` and ```end_index = num_train_samples + num_val_samples``` to use the next $25%$ of the data.\n",
    "\n",
    "Finally, for the test dataset, we’ll pass ```start_index = num_train_samples + num_val_samples``` to use the remaining samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de3e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "sampling_rate = 6\n",
    "sequence_length = 120\n",
    "delay = sampling_rate * (sequence_length + 24 - 1)\n",
    "batch_size = 256\n",
    "\n",
    "train_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    start_index=0,\n",
    "    end_index=num_train_samples)\n",
    "\n",
    "val_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    start_index=num_train_samples,\n",
    "    end_index=num_train_samples + num_val_samples)\n",
    "\n",
    "test_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    start_index=num_train_samples + num_val_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a320c2",
   "metadata": {},
   "source": [
    "### Inspecting the output of one of our datasets\n",
    "Each dataset yields a tuple ```(samples, targets)```, where ```samples``` is a batch of $256$ samples, each containing $120$ consecutive hours of input data, and ```targets``` is the corresponding array of $256$ target temperatures.\n",
    "\n",
    "Note that the samples are randomly shuffled, so two consecutive sequences in a batch (like samples[0] and samples[1]) aren’t necessarily temporally close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6818ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for samples, targets in train_dataset:\n",
    "    print(\"samples shape:\", samples.shape)\n",
    "    print(\"targets shape:\", targets.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21310791",
   "metadata": {},
   "source": [
    "## A common-sense, non-machine learning baseline\n",
    "Before we start using black-box deep learning models to solve the temperature-prediction problem, let’s try a simple, **common-sense approach**. It will serve as a sanity check, and it will establish a baseline that we’ll have to beat in order to demonstrate the usefulness of more-advanced machine learning models. Such common-sense baselines can be useful when you’re approaching a new problem for which there is no known solution (yet).\n",
    "\n",
    "A classic example is that of unbalanced classification tasks, where some classes are much more common than others. If your dataset contains 90% instances of class A and 10% instances of class B, then a common-sense approach to the classification task is to always predict “A” when presented with a new sample. Such a classifier is 90% accurate overall, and any learning-based approach should therefore beat this 90% score in order to demonstrate usefulness. Sometimes, such elementary\n",
    "baselines can prove surprisingly hard to beat.\n",
    "\n",
    "In this case, the temperature timeseries can safely be assumed to be continuous (the temperatures tomorrow are likely to be close to the temperatures today) as well as periodical with a daily period. Thus a common-sense approach is to always\n",
    "predict that the temperature 24 hours from now will be equal to the temperature right now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300b571a",
   "metadata": {},
   "source": [
    "### Computing the common-sense baseline MAE\n",
    "Let’s evaluate the approach we discussed, using the mean absolute error (MAE) metric, defined as follows:\n",
    "```math\n",
    "\tnp.mean(np.abs(preds - targets))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8add5920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_naive_method(dataset):\n",
    "    total_abs_err = 0.\n",
    "    samples_seen = 0\n",
    "    for samples, targets in dataset:\n",
    "        preds = samples[:, -1, 1] * std[1] + mean[1]\n",
    "        total_abs_err += np.sum(np.abs(preds - targets))\n",
    "        samples_seen += samples.shape[0]\n",
    "    return total_abs_err / samples_seen\n",
    "\n",
    "print(f\"Validation MAE: {evaluate_naive_method(val_dataset):.2f}\")\n",
    "print(f\"Test MAE: {evaluate_naive_method(test_dataset):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eeac76",
   "metadata": {},
   "source": [
    "## Let's try a basic machine learning model\n",
    "In the same way that it’s useful to establish a common-sense baseline before trying machine learning approaches, it’s useful to try simple, cheap machine learning models (such as small, densely connected networks) before looking into complicated and computationally expensive models such as RNNs. This is the best way to make sure any further complexity you throw at the problem is legitimate and delivers real benefits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d6c60a",
   "metadata": {},
   "source": [
    "### Training and evaluating a densely connected model\n",
    "We define a fully connected model that starts by flattening the data and then runs it through two _Dense_ layers.\n",
    "\n",
    "Note the lack of an activation function on the last _Dense_ layer, which is typical for a regression problem.\n",
    "\n",
    "We use **mean squared error** (MSE) as the loss, rather than MAE, because unlike MAE, it’s smooth\n",
    "around zero, which is a useful property for gradient descent.\n",
    "\n",
    "We will monitor MAE by adding it as a metric in ```compile()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0306771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "x = layers.Flatten()(inputs)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"jena_dense.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=10,\n",
    "                    validation_data=val_dataset,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"jena_dense.keras\")\n",
    "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4447b9",
   "metadata": {},
   "source": [
    "### Plotting results\n",
    "Let’s display the loss curves for validation and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46275d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history[\"mae\"]\n",
    "val_loss = history.history[\"val_mae\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training MAE\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation MAE\")\n",
    "plt.title(\"Training and validation MAE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbc3558",
   "metadata": {},
   "source": [
    "Some of the validation losses are close to the no-learning baseline, but not reliably. This goes to show the merit of having this baseline in the first place: it turns out to be not easy to outperform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cd7d4d",
   "metadata": {},
   "source": [
    "## Let's try a 1D convolutional model\n",
    "Since our input sequences feature daily cycles, perhaps a convolutional model could work. A temporal convnet could reuse the same representations across different days, much like a spatial convnet can reuse the same representations across different locations in an image.\n",
    "\n",
    "We already used ```Conv2D``` and ```SeparableConv2D``` layers, which see their inputs through small windows that swipe across 2D grids. There are also 1D and even 3D versions of these layers: ```Conv1D```, ```SeparableConv1D```, and ```Conv3D```.\n",
    "\n",
    "The ```Conv1D``` layer relies on 1D windows that slide across input sequences, and the ```Conv3D``` layer relies on\n",
    "cubic windows that slide across input volumes.\n",
    "\n",
    "You can thus build 1D convnets, strictly analogous to 2D convnets. They’re a great fit for any sequence data that follows the translation invariance assumption (meaning that if you slide a window over the sequence, the content of the window should follow the same properties independently of the location of the window).\n",
    "\n",
    "Let’s try one on our temperature-forecasting problem. We’ll pick an initial window length of 24, so that we look at 24 hours of data at a time (one cycle). As we downsample the sequences (via ```MaxPooling1D``` layers), we’ll reduce the window size accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292c8b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "x = layers.Conv1D(8, 24, activation=\"relu\")(inputs)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = layers.Conv1D(8, 12, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = layers.Conv1D(8, 6, activation=\"relu\")(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"jena_conv.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=10,\n",
    "                    validation_data=val_dataset,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"jena_conv.keras\")\n",
    "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1ad6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history[\"mae\"]\n",
    "val_loss = history.history[\"val_mae\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training MAE\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation MAE\")\n",
    "plt.title(\"Training and validation MAE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b89de15",
   "metadata": {},
   "source": [
    "As it turns out, this model performs even worse than the densely connected one.\n",
    "\n",
    "_What went wrong here?_ Two things:\n",
    "1. **Weather data doesn’t quite respect the translation invariance assumption**. While the data does feature daily cycles, data from a morning follows different properties than data from an evening or from the middle of the night. Weather data is only translation-invariant for a very specific timescale.\n",
    "2. **Order in our data matters**. The recent past is far more informative for predicting the next day’s temperature than data from five days ago. A 1D convnet is not able to leverage this fact. In particular, our max pooling and global average pooling layers are largely destroying order information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee31b993",
   "metadata": {},
   "source": [
    "## A first recurrent baseline\n",
    "Neither the fully connected approach nor the convolutional approach did well, but that doesn’t mean machine learning isn’t applicable to this problem. The densely connected approach first flattened the timeseries, which removed the notion of time\n",
    "from the input data. The convolutional approach treated every segment of the data in the same way, even applying pooling, which destroyed order information.\n",
    "\n",
    "Let’s instead look at the data as what it is: a sequence, where causality and order matter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038f03ea",
   "metadata": {},
   "source": [
    "### A simple LSTM-based model\n",
    "There’s a family of neural network architectures designed specifically for this use case: **recurrent neural networks** (RNNs). Among them, the **Long Short Term Memory** (LSTM) layer has long been very popular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04dda23",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "x = layers.LSTM(16)(inputs)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"jena_lstm.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=10,\n",
    "                    validation_data=val_dataset,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"jena_lstm.keras\")\n",
    "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4a62e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history[\"mae\"]\n",
    "val_loss = history.history[\"val_mae\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training MAE\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation MAE\")\n",
    "plt.title(\"Training and validation MAE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a85eae5",
   "metadata": {},
   "source": [
    "The LSTM-based model can finally beat the common-sense baseline (albeit just by a bit, for now), demonstrating the value of machine learning on this task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
