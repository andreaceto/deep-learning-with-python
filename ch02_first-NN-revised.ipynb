{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Reshaping\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple Dense class\n",
    "Let’s implement a simple Python class, _NaiveDense_, that creates two TensorFlow\n",
    "variables, **W** and **b**, and exposes a **\\_\\_call\\_\\_()** method that applies the following transformation:\n",
    "```\n",
    "output = activation(dot(W, input) + b)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveDense:\n",
    "\tdef __init__(self, input_size, output_size, activation):\n",
    "\t\tself.activation = activation\n",
    "\n",
    "\t\t# Create a matrix, W, of shape (input_size, output_size) initialized with random values\n",
    "\t\tw_shape = (input_size, output_size)\n",
    "\t\tw_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
    "\t\tself.W = tf.Variable(w_initial_value)\n",
    "\n",
    "\t\t# Create a vector, b, of shape (output_size), initialized with zeros\n",
    "\t\tb_shape = (output_size,)\n",
    "\t\tb_initial_value = tf.zeros(b_shape)\n",
    "\t\tself.b = tf.Variable(b_initial_value)\n",
    "\n",
    "\t# Apply the forward pass\n",
    "\tdef __call__(self, inputs):\n",
    "\t\treturn self.activation(tf.matmul(inputs, self.W) + self.b)\n",
    "\n",
    "\t# Convenience method for retrieving the layer's weights\n",
    "\t@property\n",
    "\tdef weights(self):\n",
    "\t\treturn [self.W, self.b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple Sequential class\n",
    "Now, let’s create a _NaiveSequential_ class to chain these layers. It wraps a list of layers\n",
    "and exposes a **\\_\\_call\\_\\_()** method that simply calls the underlying layers on the\n",
    "inputs, in order. It also features a _weights_ property to easily keep track of the layers’\n",
    "parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveSequential:\n",
    "\tdef __init__(self, layers):\n",
    "\t\tself.layers = layers\n",
    "\n",
    "\tdef __call__(self, inputs):\n",
    "\t\tx = inputs  # Start with the input data\n",
    "\t\tfor layer in self.layers:\n",
    "\t\t   x = layer(x)  # Apply each layer to the data sequentially\n",
    "\t\treturn x\n",
    "\n",
    "\t@property\n",
    "\tdef weights(self):\n",
    "\t   weights = []  # Initialize an empty list to collect weights\n",
    "\t   for layer in self.layers:\n",
    "\t\t   weights += layer.weights  # Add the weights of the current layer to the list\n",
    "\t   return weights  # Return the list of all weights from all layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mock Keras model\n",
    "Using this _NaiveDense_ class and this _NaiveSequential_ class, we can create a mock Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveSequential([\n",
    "\t# First dense layer: takes input of size 28x28 (flattened image), outputs 512 features with ReLU activation\n",
    "\tNaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
    "\t# Second dense layer: takes 512 inputs from the previous layer, outputs 10 class scores with softmax activation\n",
    "\tNaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
    "])\n",
    "# Check that the model has exactly 4 weight tensors:\n",
    "# Each NaiveDense layer has 2 weight tensors: one for weights (W), one for biases (b)\n",
    "# So 2 layers × 2 weights each = 4 weights in total\n",
    "assert len(model.weights) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Generator\n",
    "We need a way to iterate over the MNIST data in mini-batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class BatchGenerator:\n",
    "\tdef __init__(self, images, labels, batch_size=128):\n",
    "\t\t# Ensure the number of images and labels are the same\n",
    "\t\tassert len(images) == len(labels)\n",
    "\t\t\n",
    "\t\tself.index = 0  # Start index for batching\n",
    "\t\tself.images = images  # Dataset of input images\n",
    "\t\tself.labels = labels  # Corresponding labels for the images\n",
    "\t\tself.batch_size = batch_size  # Number of samples per batch\n",
    "\t\t\n",
    "\t\t# Total number of batches needed to cover the entire dataset\n",
    "\t\tself.num_batches = math.ceil(len(images) / batch_size)\n",
    "\n",
    "\tdef next(self):\n",
    "\t\t# Select a slice of images and labels from the current index up to index + batch_size\n",
    "\t\timages = self.images[self.index : self.index + self.batch_size]\n",
    "\t\tlabels = self.labels[self.index : self.index + self.batch_size]\n",
    "\n",
    "\t\t# Move the index forward by batch_size for the next call\n",
    "\t\tself.index += self.batch_size\n",
    "\n",
    "\t\t# Return the current batch of images and labels\n",
    "\t\treturn images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running one training step\n",
    "The most difficult part of the process is the “training step”: updating the weights of\n",
    "the model after running it on one batch of data.\n",
    "\n",
    "We need to:\n",
    "1. Compute the predictions of the model for the images in the batch.\n",
    "2. Compute the loss value for these predictions, given the actual labels.\n",
    "3. Compute the gradient of the loss with regard to the model’s weights.\n",
    "4. Move the weights by a small amount in the direction opposite to the gradient.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the “weight update” step (represented by ```update_weights``` function) is to move the weights by “a bit” in a direction that will reduce the loss on this batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "lr = 1e-3  # the \"learning rate\" determines the magnitude of the step towards the loss minimum\n",
    "optimizer = optimizers.SGD(lr)\n",
    "\n",
    "def update_weights(gradients, weights):\n",
    "\toptimizer.apply_gradients(zip(gradients, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_training_step(model, images_batch, labels_batch):\n",
    "\twith tf.GradientTape() as tape:\n",
    "\t\t# Run the \"forward pass\" (compute the model-s predictions under a GradientTape scope)\n",
    "\t\tpredictions = model(images_batch)\n",
    "\t\tper_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "\t\t\tlabels_batch, predictions)\n",
    "\t\taverage_loss = tf.reduce_mean(per_sample_losses)\n",
    "\t\n",
    "\t# Compute the gradient of the loss with regard to the weights\n",
    "\t# \"gradients\" is a list where each entry corresponds to a weight from the model.weights list\n",
    "\tgradients = tape.gradient(average_loss, model.weights) \n",
    "\t\n",
    "\t# Update the weights using the gradients\n",
    "\tupdate_weights(gradients, model.weights)\n",
    "\t\n",
    "\treturn average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The full training loop\n",
    "An epoch of training simply consists of repeating the training step for each batch in the training data, and the full training loop is simply the repetition of one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, images, labels, epochs, batch_size=128):\n",
    "\tfor epoch_counter in range(epochs):\n",
    "\t\tprint(f\"Epoch {epoch_counter}\")\n",
    "\t\tbatch_generator = BatchGenerator(images, labels)\n",
    "\t\tfor batch_counter in range(batch_generator.num_batches):\n",
    "\t\t\timages_batch, labels_batch = batch_generator.next()\n",
    "\t\t\tloss = one_training_step(model, images_batch, labels_batch)\n",
    "\t\t\tif batch_counter % 100 == 0:\n",
    "\t\t\t\tprint(f\"loss at batch {batch_counter}: {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "loss at batch 0: 6.58\n",
      "loss at batch 100: 2.20\n",
      "loss at batch 200: 2.16\n",
      "loss at batch 300: 2.05\n",
      "loss at batch 400: 2.20\n",
      "Epoch 1\n",
      "loss at batch 0: 1.89\n",
      "loss at batch 100: 1.85\n",
      "loss at batch 200: 1.79\n",
      "loss at batch 300: 1.68\n",
      "loss at batch 400: 1.82\n",
      "Epoch 2\n",
      "loss at batch 0: 1.56\n",
      "loss at batch 100: 1.56\n",
      "loss at batch 200: 1.47\n",
      "loss at batch 300: 1.40\n",
      "loss at batch 400: 1.50\n",
      "Epoch 3\n",
      "loss at batch 0: 1.31\n",
      "loss at batch 100: 1.32\n",
      "loss at batch 200: 1.22\n",
      "loss at batch 300: 1.19\n",
      "loss at batch 400: 1.27\n",
      "Epoch 4\n",
      "loss at batch 0: 1.11\n",
      "loss at batch 100: 1.14\n",
      "loss at batch 200: 1.03\n",
      "loss at batch 300: 1.03\n",
      "loss at batch 400: 1.11\n",
      "Epoch 5\n",
      "loss at batch 0: 0.97\n",
      "loss at batch 100: 1.01\n",
      "loss at batch 200: 0.89\n",
      "loss at batch 300: 0.91\n",
      "loss at batch 400: 0.99\n",
      "Epoch 6\n",
      "loss at batch 0: 0.86\n",
      "loss at batch 100: 0.90\n",
      "loss at batch 200: 0.79\n",
      "loss at batch 300: 0.83\n",
      "loss at batch 400: 0.90\n",
      "Epoch 7\n",
      "loss at batch 0: 0.78\n",
      "loss at batch 100: 0.82\n",
      "loss at batch 200: 0.71\n",
      "loss at batch 300: 0.76\n",
      "loss at batch 400: 0.84\n",
      "Epoch 8\n",
      "loss at batch 0: 0.72\n",
      "loss at batch 100: 0.75\n",
      "loss at batch 200: 0.65\n",
      "loss at batch 300: 0.70\n",
      "loss at batch 400: 0.78\n",
      "Epoch 9\n",
      "loss at batch 0: 0.67\n",
      "loss at batch 100: 0.70\n",
      "loss at batch 200: 0.60\n",
      "loss at batch 300: 0.66\n",
      "loss at batch 400: 0.74\n"
     ]
    }
   ],
   "source": [
    "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model\n",
    "We can evaluate the model by taking the _argmax_ of its predictions over the test images,\n",
    "and comparing it to the expected labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = model(test_images)\n",
    "predictions = predictions.numpy()\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "matches = predicted_labels == test_labels\n",
    "print(f\"accuracy: {matches.mean():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
